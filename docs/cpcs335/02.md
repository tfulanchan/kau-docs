---
sidebar_position: 2
title: Deep learning
---

## Artificial Neural Networks

What are artificial neural networks?

Artificial neural networks are a type of machine learning model that mimic the human brain to learn and make decisions.

Components of artificial neural networks

### Why are artificial neural networks important?

Big Data Handling: In today's data-driven world, abundant data is available. Artificial Neural Networks can handle and process large datasets, extracting meaningful insights that might be otherwise difficult to uncover

Complex Pattern Recognition: Artificial Neural Networks can recognize intricate patterns and relationships in data that might be challenging for traditional models. This makes them well-suited for tasks like image recognition, speech recognition, and natural language processing.

Flexibility: Artificial Neural Networks can be applied to various tasks, from regression and classification to generative tasks like image and text generation. This versatility makes them a valuable tool in various domains.

How do Artificial Neural Networks Work?

## Deep learning: end-to-end learning

Deep learning is a subset of machine learning that involves using artificial neural networks (ANNs) with multiple layers, also known as deep neural networks. These networks are designed to automatically learn patterns and representations from data by progressively extracting higher-level features through a hierarchy of layers.

The "deep" in deep learning refers to many hidden layers in these neural networks

### Artificial Intelligence, Machine learning & Deep learning

Artificial intelligence is the broader concept of creating intelligent machines that can mimic human-like behaviour.

Machine learning is a subset of AI that involves algorithms learning from data to improve their performance on specific tasks.

Deep learning is a subset of machine learning that utilizes deep neural networks to automatically learn complex patterns and representations from data.

### Machine learning vs.. Deep learning

Feature extraction is a significant step in traditional machine learning pipelines, where domain knowledge and handcrafted algorithms extract relevant features from raw data before feeding them into machine learning models.

Feature extraction selects or transforms important data elements to minimise dimensionality and highlight task-relevant features.

Deep learning automatically extract features from raw input, which has reduced the need for extensive manual feature engineering in many cases.

Deep learning models, especially in tasks like image classification, object detection, speech recognition, and machine translation, are designed to learn directly from raw data (e.g., images, audio waveforms, text).

This is known as end-to-end learning, where the model learns both feature extraction and the final task in a unified manner. This approach has proven highly effective, reducing the need for handcrafted feature engineering.

## Computer vision: enabling a machine to interpret the scene

What is computer vision?

Computer vision is a branch of artificial intelligence that focuses on enabling machines to interpret and understand visual information from the world around us. It involves developing algorithms and techniques that allow computers to analyse, process, and make sense of images and videos

Using images from cameras and videos, deep learning models enable machines to accurately identify and classify the objects.

The scene refers to the environment or the object being observed. In human vision, the scene is captured by the eyes and processed by the brain. In computer vision, the scene is captured by a sensing device such as a camera or a scanner.

| Data source | Description |
| --- | --- |
| Thermal Images | Captured using infrared cameras, these images represent temperature differences in a scene. |
| Satellite Image | High-resolution images captured by satellites, often used for mapping, agriculture, and environmental monitoring. |
| Medical Image | Specialized images from devices like X-rays, MRIs, CT scans, and ultrasounds. |
| Grayscale Images | Black and white or monochromatic images. |
| Recorded Videos | Stored video files from various sources. |
| Real-time Streams | Such as feeds from CCTV or webcams. |

Sensing device

In computer vision, the sensing device is typically a camera or a sensor array that captures visual information from the environment

Computer vision

Once the image/ video is captured, it undergoes various processing stages, depending on the task. These stages can include pre-processing (image processing), feature extraction, and final interpretation using computer vision algorithms.

Human vision vs. computer vision

### Computer vision vs. image processing

Computer vision seeks to enable computers to interpret and make decisions based on visual data, similarly to how humans do.

Image processing deals with manipulating images to achieve the desired output, often improving the image's quality or extracting certain features.

Images and Videos: Navigating the Breadth of Visual Data Types

### The importance of computer vision in today's world

The surge of visual content

Given the vast amounts of visual content, there's an urgent need for AI algorithms to automatically analyses and interpret these videos, a task beyond human capacity.

Automation and Efficiency

Computer vision can automate tasks that humans previously performed such as driving cars.

Facilitating Realtime Processing

Real-time visual data interpretation is crucial. Computer vision allows for instantaneous analysis, ensuring timely reactions to dynamic situations.

Empowering decision-making

By enabling machines to 'see' and 'understand' visual data, computer vision supports more informed and rapid decision-making processes for individuals and businesses.

### Computer vision primary tasks

Recognition: Classify images into predefined classes or categories. This involves training a model to categorize images into predefined classes or categories, such as classifying whether an image contains a cat or a dog.

+ Face Resonation
+ Optical Character Resonation (OCR)

Detection: Object detection goes beyond classification by identifying objects in an image and providing their precise location through bounding boxes. Object detection goes beyond classification by identifying objects in an image and providing their precise location through bounding boxes. 

+ Autonomous Vehicles: Detecting pedestrians, vehicles, and obstacles on the road.
+ Retail: Tracking products on store shelves for inventory management.
+ Industrial Automation: Identifying defects in manufacturing processes.
+ Agriculture: Monitoring and managing crops and livestock

Segmentation: Label each pixel in an image with the corresponding object class. Dividing an image into multiple segments or regions, each corresponding to a meaningful part of the image. Image segmentation aims to partition an image into regions with similar properties, such as color, intensity, texture, or object boundaries.

+ Medical Imaging: helps identify and isolate specific structures or abnormalities in images,
+ Satellite and Remote Sensing: Image segmentation is used in satellite and remote sensing applications to analyze and classify land cover
+ Image Editing: Image segmentation is essential for tasks like image background removal, object extraction, and image editing.

Tracking: Following the movement of an object across a sequence of images or frames in a video. Object tracking involves following the movement of an object across a sequence of images or frames in a video.

+ Road Condition Monitoring : Tracking people and vehicles in security cameras.
+ Autonomous Vehicles: Tracking other vehicles and pedestrians for collision avoidance.
+ Sports Analysis: Tracking players and the ball in sports videos.
+ Augmented Reality (AR): Tracking objects or markers for AR applications.
+ Robotics: Enabling robots to track and manipulate objects.

Pose Estimation: Aims to determine the position and orientation of objects or people in an image. Aims to determine the position and orientation (pose) of an object or a person in an image or a video frame. It involves identifying the key points, landmarks, or joints on the object or person and estimating their 2D or 3D positions in the image or video. 

+ Virtual Reality: In VR applications to track the position and movement of the user's body.
+ Gesture Recognition: For controlling devices or systems through hand or body gestures.
+ Healthcare: In physical therapy and sports training to monitor body movements and posture.

### Computer vision applications

Security: It is vital for security applications such as facial recognition, object detection, and anomaly detection. It is used in surveillance systems, access control, and fraud detection.

Medical Diagnosis and Healthcare: It aids in medical image analysis, helping doctors detect diseases, tumours, and anomalies in X-rays, MRIs, and CT scans. It can also be used in monitoring patient movement and vital signs.

Retail and E-commerce: It is used in retail for inventory management, customer analytics, and personalized shopping recommendations. It can also power visual search engines, allowing users to find products based on images.

Agriculture: Precision agriculture uses computer vision to monitor crop health, detect diseases, and optimize resource allocation. This can lead to higher crop yields and more sustainable farming practices.

Automotive Industry: Computer vision is used for autonomous driving, driver assistance systems, and traffic management.

Environmental Monitoring: It can be employed in monitoring and analysing satellite and drone imagery for environmental purposes, such as tracking deforestation, studying climate change, and assessing wildlife populations.

Accessibility: It can improve the accessibility of digital content for individuals with disabilities. It can be used for text-to-speech conversion, gesture recognition, and navigation assistance.

Scientific Research: It is used in various scientific disciplines, such as astronomy, biology, and geology, to analyse and interpret visual data, aiding researchers in their studies.

Computer vision and robotics

Computer vision is critical in robotics, allowing machines to perceive and interact with their environment in real-time. Using sensors and cameras, robots can navigate complex environments and manipulate objects with precision and accuracy.

For example, self-driving cars use computer vision to detect obstacles and pedestrians on the road, enabling them to make split-second decisions to avoid collisions. In manufacturing, robots with computer vision can identify and sort objects on an assembly line, improving efficiency and reducing errors. Additionally, drones with computer vision capabilities can be used for search and rescue missions, as they can quickly scan large areas and identify potential hazards.

Computer Vision and Augmented Reality

Augmented reality (AR) is a technology that overlays digital information into the real world. Computer vision plays a crucial role in AR by enabling devices to recognize and track objects in the environment. This allows AR applications to integrate virtual content with the physical world seamlessly.

Image recognition and overlay involve using computer vision algorithms to identify objects in the real world and superimpose digital content onto them. For example, an AR application might use computer vision to recognize a city skyline picture and overlay information about each building onto the image. This creates an immersive and interactive experience for users.

### Ethics and privacy in computer vision

As computer vision technology becomes more advanced and widespread, it is important to consider the ethical and privacy concerns that come with it.

+ Data Collection and Consent
+ Bias and Discrimination
+ Deep fakes and Manipulation
+ Personal Data Leaks
+ Automated Decisions without Accountability
+ Loss of Anonymity in Public Spaces
+ Over-reliance and Trust